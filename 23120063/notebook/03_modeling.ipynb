{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Modeling và Đánh Giá Mô Hình\n",
    "## HR Analytics: Job Change of Data Scientists\n",
    "\n",
    "**Sử dụng hoàn toàn các thuật toán implement từ đầu trong models.py**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "BASE_DIR = os.path.abspath(\"..\")\n",
    "sys.path.append(BASE_DIR)\n",
    "\n",
    "from src.models import LinearRegression, LogisticRegression, KNN, EvaluationMetrics, CrossValidation, StandardScaler\n",
    "from src.data_processing import load_data, handle_missing_values, encode_and_engineer_features, normalize_minmax\n",
    "from src.visualization import plot_target_distribution, plot_feature_vs_target\n",
    "\n",
    "print(\"Tất cả thư viện đã được import thành công!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Tải và Chuẩn bị Dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tải dữ liệu\n",
    "print(\"Đang tải dữ liệu...\")\n",
    "data = load_data('../data/raw/aug_train.csv')\n",
    "\n",
    "if data is not None:\n",
    "    print(f\"Dữ liệu được tải thành công! Shape: {data.shape}\")\n",
    "    print(f\"Các cột: {data.dtype.names}\")\n",
    "    \n",
    "    # Hiển thị phân phối target\n",
    "    plot_target_distribution(data)\n",
    "else:\n",
    "    print(\"Lỗi khi tải dữ liệu!\")\n",
    "    # Tạo dữ liệu mẫu để demo\n",
    "    print(\"Tạo dữ liệu mẫu để demo...\")\n",
    "    np.random.seed(42)\n",
    "    n_samples = 1000\n",
    "    \n",
    "    # Tạo structured array với các features quan trọng\n",
    "    data = np.zeros(n_samples, dtype=[\n",
    "        ('city_development_index', 'f8'),\n",
    "        ('training_hours', 'f8'), \n",
    "        ('target', 'f8'),\n",
    "        ('gender', 'U10'),\n",
    "        ('relevent_experience', 'U10'),\n",
    "        ('education_level', 'U10'),\n",
    "        ('experience', 'U10'),\n",
    "        ('enrolled_university', 'U10'),\n",
    "        ('major_discipline', 'U10')\n",
    "    ])\n",
    "    \n",
    "    # Tạo dữ liệu giả lập\n",
    "    data['city_development_index'] = np.random.uniform(0.5, 1.0, n_samples)\n",
    "    data['training_hours'] = np.random.exponential(50, n_samples)\n",
    "    data['target'] = np.random.choice([0, 1], n_samples, p=[0.7, 0.3])\n",
    "    data['gender'] = np.random.choice(['Male', 'Female', 'Other'], n_samples, p=[0.6, 0.35, 0.05])\n",
    "    data['relevent_experience'] = np.random.choice(['Has relevent experience', 'No relevent experience'], n_samples)\n",
    "    data['education_level'] = np.random.choice(['Graduate', 'Masters', 'High School'], n_samples, p=[0.6, 0.3, 0.1])\n",
    "    data['experience'] = np.random.choice(['<1', '2', '5', '10', '>20'], n_samples)\n",
    "    data['enrolled_university'] = np.random.choice(['no_enrollment', 'Part time course', 'Full time course'], n_samples)\n",
    "    data['major_discipline'] = np.random.choice(['STEM', 'Business Degree', 'Arts'], n_samples)\n",
    "    \n",
    "    print(\"Dữ liệu mẫu đã được tạo!\")\n",
    "    plot_target_distribution(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tiền xử lý Dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 2: TIỀN XỬ LÝ DỮ LIỆU\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Xử lý missing values\n",
    "print(\"1. Xử lý missing values...\")\n",
    "data_processed = handle_missing_values(data)\n",
    "\n",
    "# Encode và engineering features\n",
    "print(\"2. Encoding và feature engineering...\")\n",
    "X, y = encode_and_engineer_features(data_processed)\n",
    "\n",
    "print(f\"Shape của X: {X.shape}\")\n",
    "print(f\"Shape của y: {y.shape if y is not None else 'None'}\")\n",
    "print(f\"Số features: {X.shape[1]}\")\n",
    "\n",
    "# Chuẩn hóa dữ liệu\n",
    "print(\"3. Chuẩn hóa dữ liệu...\")\n",
    "X_normalized = normalize_minmax(X)\n",
    "\n",
    "print(\"Tiền xử lý hoàn tất!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chia Dữ liệu Train-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 3: CHIA DỮ LIỆU TRAIN-TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sử dụng custom train_test_split từ models.py\n",
    "X_train, X_test, y_train, y_test = CrossValidation.train_test_split(\n",
    "    X_normalized, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# Kiểm tra phân phối target\n",
    "print(\"\\nPhân phối target trong tập train:\")\n",
    "unique_train, counts_train = np.unique(y_train, return_counts=True)\n",
    "for val, count in zip(unique_train, counts_train):\n",
    "    print(f\"  Target {val}: {count} samples ({count/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nPhân phối target trong tập test:\")\n",
    "unique_test, counts_test = np.unique(y_test, return_counts=True)\n",
    "for val, count in zip(unique_test, counts_test):\n",
    "    print(f\"  Target {val}: {count} samples ({count/len(y_test)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Huấn luyện Mô hình Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 4: HUẤN LUYỆN LOGISTIC REGRESSION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Khởi tạo và huấn luyện mô hình\n",
    "log_reg = LogisticRegression(learning_rate=0.1, n_iterations=1000)\n",
    "print(\"Đang huấn luyện Logistic Regression...\")\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Vẽ đồ thị loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(log_reg.losses)\n",
    "plt.title('Loss during Training - Logistic Regression')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Binary Cross-Entropy Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Zoom vào 100 iterations cuối\n",
    "plt.plot(log_reg.losses[-100:])\n",
    "plt.title('Loss (Last 100 Iterations)')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final loss: {log_reg.losses[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Đánh giá Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 5: ĐÁNH GIÁ LOGISTIC REGRESSION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Dự đoán trên tập test\n",
    "y_pred_proba = log_reg.predict_proba(X_test)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "# Tính các metrics\n",
    "accuracy = EvaluationMetrics.accuracy(y_test, y_pred)\n",
    "precision = EvaluationMetrics.precision(y_test, y_pred)\n",
    "recall = EvaluationMetrics.recall(y_test, y_pred)\n",
    "f1 = EvaluationMetrics.f1_score(y_test, y_pred)\n",
    "conf_matrix = EvaluationMetrics.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"KẾT QUẢ LOGISTIC REGRESSION:\")\n",
    "print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall:    {recall:.4f}\")\n",
    "print(f\"F1-Score:  {f1:.4f}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
    "\n",
    "# Vẽ confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Predicted 0', 'Predicted 1'],\n",
    "            yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "# Vẽ phân phối xác suất\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(y_pred_proba[y_test == 0], bins=30, alpha=0.7, label='Actual 0', color='blue')\n",
    "plt.hist(y_pred_proba[y_test == 1], bins=30, alpha=0.7, label='Actual 1', color='red')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Predicted Probabilities')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# ROC curve đơn giản\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "tpr = []\n",
    "fpr = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    y_pred_thresh = (y_pred_proba >= threshold).astype(int)\n",
    "    tp = np.sum((y_pred_thresh == 1) & (y_test == 1))\n",
    "    fp = np.sum((y_pred_thresh == 1) & (y_test == 0))\n",
    "    tn = np.sum((y_pred_thresh == 0) & (y_test == 0))\n",
    "    fn = np.sum((y_pred_thresh == 0) & (y_test == 1))\n",
    "    \n",
    "    tpr.append(tp / (tp + fn) if (tp + fn) > 0 else 0)\n",
    "    fpr.append(fp / (fp + tn) if (fp + tn) > 0 else 0)\n",
    "\n",
    "plt.plot(fpr, tpr, marker='.')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Logistic Regression')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Huấn luyện và Đánh giá KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 6: HUẤN LUYỆN VÀ ĐÁNH GIÁ K-NEAREST NEIGHBORS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Thử nghiệm với các giá trị k khác nhau\n",
    "k_values = [3, 5, 7, 9, 11]\n",
    "knn_results = []\n",
    "\n",
    "for k in k_values:\n",
    "    print(f\"\\nĐang huấn luyện KNN với k={k}...\")\n",
    "    knn = KNN(k=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred_knn = knn.predict(X_test)\n",
    "    \n",
    "    accuracy = EvaluationMetrics.accuracy(y_test, y_pred_knn)\n",
    "    precision = EvaluationMetrics.precision(y_test, y_pred_knn)\n",
    "    recall = EvaluationMetrics.recall(y_test, y_pred_knn)\n",
    "    f1 = EvaluationMetrics.f1_score(y_test, y_pred_knn)\n",
    "    \n",
    "    knn_results.append({\n",
    "        'k': k,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    })\n",
    "    \n",
    "    print(f\"K={k}: Accuracy={accuracy:.4f}, F1-Score={f1:.4f}\")\n",
    "\n",
    "# Chọn k tốt nhất dựa trên F1-Score\n",
    "best_knn = max(knn_results, key=lambda x: x['f1'])\n",
    "print(f\"\\nKNN tốt nhất: k={best_knn['k']}\")\n",
    "print(f\"Accuracy:  {best_knn['accuracy']:.4f}\")\n",
    "print(f\"Precision: {best_knn['precision']:.4f}\")\n",
    "print(f\"Recall:    {best_knn['recall']:.4f}\")\n",
    "print(f\"F1-Score:  {best_knn['f1']:.4f}\")\n",
    "\n",
    "# Vẽ so sánh hiệu suất KNN\n",
    "plt.figure(figsize=(10, 6))\n",
    "metrics = ['accuracy', 'precision', 'recall', 'f1']\n",
    "x = range(len(k_values))\n",
    "\n",
    "for i, metric in enumerate(metrics):\n",
    "    values = [result[metric] for result in knn_results]\n",
    "    plt.plot(x, values, marker='o', label=metric.capitalize())\n",
    "\n",
    "plt.xticks(x, k_values)\n",
    "plt.xlabel('k value')\n",
    "plt.ylabel('Score')\n",
    "plt.title('KNN Performance for Different k Values')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 7: CROSS-VALIDATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Cross-validation cho Logistic Regression\n",
    "print(\"Cross-validation cho Logistic Regression...\")\n",
    "cv_scores_lr = CrossValidation.cross_val_score(\n",
    "    LogisticRegression(learning_rate=0.1, n_iterations=500),\n",
    "    X_normalized, y, cv=5, scoring='f1'\n",
    ")\n",
    "\n",
    "print(f\"Logistic Regression CV F1-Scores: {cv_scores_lr}\")\n",
    "print(f\"Mean F1-Score: {np.mean(cv_scores_lr):.4f} (+/- {np.std(cv_scores_lr):.4f})\")\n",
    "\n",
    "# Cross-validation cho KNN\n",
    "print(\"\\nCross-validation cho KNN...\")\n",
    "cv_scores_knn = CrossValidation.cross_val_score(\n",
    "    KNN(k=best_knn['k']),\n",
    "    X_normalized, y, cv=5, scoring='f1'\n",
    ")\n",
    "\n",
    "print(f\"KNN CV F1-Scores: {cv_scores_knn}\")\n",
    "print(f\"Mean F1-Score: {np.mean(cv_scores_knn):.4f} (+/- {np.std(cv_scores_knn):.4f})\")\n",
    "\n",
    "# So sánh kết quả cross-validation\n",
    "plt.figure(figsize=(10, 6))\n",
    "models = ['Logistic Regression', 'KNN']\n",
    "means = [np.mean(cv_scores_lr), np.mean(cv_scores_knn)]\n",
    "stds = [np.std(cv_scores_lr), np.std(cv_scores_knn)]\n",
    "\n",
    "bars = plt.bar(models, means, yerr=stds, capsize=10, \n",
    "              color=['skyblue', 'lightcoral'], alpha=0.7)\n",
    "plt.ylabel('F1-Score')\n",
    "plt.title('Cross-Validation Results Comparison')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Thêm giá trị lên các cột\n",
    "for bar, mean in zip(bars, means):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "             f'{mean:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. So sánh Mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 8: SO SÁNH MÔ HÌNH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Tổng hợp kết quả\n",
    "results_summary = {\n",
    "    'Logistic Regression': {\n",
    "        'accuracy': EvaluationMetrics.accuracy(y_test, y_pred),\n",
    "        'precision': EvaluationMetrics.precision(y_test, y_pred),\n",
    "        'recall': EvaluationMetrics.recall(y_test, y_pred),\n",
    "        'f1': EvaluationMetrics.f1_score(y_test, y_pred),\n",
    "        'cv_mean': np.mean(cv_scores_lr),\n",
    "        'cv_std': np.std(cv_scores_lr)\n",
    "    },\n",
    "    f\"KNN (k={best_knn['k']})\": {\n",
    "        'accuracy': best_knn['accuracy'],\n",
    "        'precision': best_knn['precision'],\n",
    "        'recall': best_knn['recall'],\n",
    "        'f1': best_knn['f1'],\n",
    "        'cv_mean': np.mean(cv_scores_knn),\n",
    "        'cv_std': np.std(cv_scores_knn)\n",
    "    }\n",
    "}\n",
    "\n",
    "# Hiển thị bảng so sánh\n",
    "print(\"BẢNG SO SÁNH MÔ HÌNH:\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Model':<25} {'Accuracy':<10} {'Precision':<10} {'Recall':<10} {'F1-Score':<10} {'CV F1':<10}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for model_name, metrics in results_summary.items():\n",
    "    print(f\"{model_name:<25} {metrics['accuracy']:.4f}    {metrics['precision']:.4f}    \"\n",
    "          f\"{metrics['recall']:.4f}    {metrics['f1']:.4f}    {metrics['cv_mean']:.4f}\")\n",
    "\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Vẽ biểu đồ so sánh\n",
    "metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1']\n",
    "models = list(results_summary.keys())\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for i, metric in enumerate(metrics_to_plot):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    values = [results_summary[model][metric] for model in models]\n",
    "    bars = plt.bar(models, values, color=['skyblue', 'lightcoral'], alpha=0.7)\n",
    "    plt.title(f'{metric.capitalize()} Comparison')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Thêm giá trị lên cột\n",
    "    for bar, value in zip(bars, values):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                f'{value:.4f}', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Dự đoán trên Dữ liệu Mới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 10: DỰ ĐOÁN TRÊN DỮ LIỆU MỚI\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Tạo dữ liệu mới giả lập để demo\n",
    "np.random.seed(123)\n",
    "n_new_samples = 10\n",
    "new_data = np.random.randn(n_new_samples, X.shape[1])\n",
    "\n",
    "# Chuẩn hóa dữ liệu mới (sử dụng cùng parameters với training data)\n",
    "new_data_normalized = normalize_minmax(new_data)\n",
    "\n",
    "# Dự đoán với Logistic Regression\n",
    "probabilities = log_reg.predict_proba(new_data_normalized)\n",
    "predictions = log_reg.predict(new_data_normalized)\n",
    "\n",
    "print(\"DỰ ĐOÁN CHO DỮ LIỆU MỚI:\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Sample':<8} {'Probability':<12} {'Prediction':<12} {'Interpretation':<15}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i in range(n_new_samples):\n",
    "    prob = probabilities[i]\n",
    "    pred = predictions[i]\n",
    "    interpretation = \"Đổi việc\" if pred == 1 else \"Không đổi việc\"\n",
    "    print(f\"{i+1:<8} {prob:.4f}      {pred:<12} {interpretation:<15}\")\n",
    "\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Phân phối dự đoán\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(probabilities, bins=20, alpha=0.7, color='purple', edgecolor='black')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Predictions for New Data')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "unique_pred, counts_pred = np.unique(predictions, return_counts=True)\n",
    "plt.pie(counts_pred, labels=['Không đổi việc', 'Đổi việc'], autopct='%1.1f%%', \n",
    "        colors=['lightblue', 'lightcoral'])\n",
    "plt.title('Prediction Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Kết luận và Phân tích"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"BƯỚC 11: KẾT LUẬN VÀ PHÂN TÍCH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Phân tích kết quả\n",
    "best_model_name = max(results_summary.keys(), \n",
    "                     key=lambda x: results_summary[x]['f1'])\n",
    "best_model_metrics = results_summary[best_model_name]\n",
    "\n",
    "print(\"KẾT LUẬN:\")\n",
    "print(f\"• Mô hình tốt nhất: {best_model_name}\")\n",
    "print(f\"• F1-Score: {best_model_metrics['f1']:.4f}\")\n",
    "print(f\"• Accuracy: {best_model_metrics['accuracy']:.4f}\")\n",
    "print(f\"• Precision: {best_model_metrics['precision']:.4f}\") \n",
    "print(f\"• Recall: {best_model_metrics['recall']:.4f}\")\n",
    "\n",
    "print(\"\\nPHÂN TÍCH HIỆU SUẤT:\")\n",
    "if best_model_metrics['precision'] > best_model_metrics['recall']:\n",
    "    print(\"• Mô hình tập trung vào Precision: ít false positives hơn\")\n",
    "    print(\"• Có thể bỏ sót một số trường hợp thực sự đổi việc\")\n",
    "else:\n",
    "    print(\"• Mô hình tập trung vào Recall: phát hiện được nhiều trường hợp đổi việc\")\n",
    "    print(\"• Có thể có nhiều false positives hơn\")\n",
    "\n",
    "\n",
    "\n",
    "# Lưu kết quả\n",
    "print(\"\\nLưu kết quả modeling...\")\n",
    "model_results = {\n",
    "    'best_model': best_model_name,\n",
    "    'metrics': best_model_metrics,\n",
    "    'logistic_regression_weights': log_reg.weights if hasattr(log_reg, 'weights') else None,\n",
    "    'feature_importance': feature_importance.tolist() if 'feature_importance' in locals() else None\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
